{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048cd2cf",
   "metadata": {},
   "source": [
    "# BERT Model Optimization with MLflow and Optuna\n",
    "\n",
    "This notebook implements hyperparameter optimization for the BERT text classification model using:\n",
    "- **Optuna**: For hyperparameter optimization\n",
    "- **MLflow**: For experiment tracking and model registry\n",
    "- **Autologging**: Automatic logging of training metrics and artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6090250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MLflow and Optuna imports\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3161208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Configuration and global parameters\n",
    "RANDOM_SEED = 42\n",
    "DATASET_PATH = \"historias_clinicas_procesadas.xlsx\"\n",
    "NCLASS = 6\n",
    "PRE_TRAINED_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "N_TRIALS = 20  # Number of Optuna trials\n",
    "SAMPLE_SIZE = 500  # Sample size for faster experimentation\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# MLflow configuration\n",
    "mlflow.set_experiment(\"BERT_Hyperparameter_Optimization\")\n",
    "mlflow.pytorch.autolog(log_models=True, log_datasets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2c6969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 500 samples\n",
      "Classes distribution:\n",
      "grupo_codificado\n",
      "0    106\n",
      "1     27\n",
      "2    151\n",
      "3    109\n",
      "4     42\n",
      "5     65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess the dataset\"\"\"\n",
    "    df = pd.read_excel(DATASET_PATH)\n",
    "    \n",
    "    # Sample data for faster experimentation\n",
    "    df = df.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    \n",
    "    # Clean text data\n",
    "    df[\"concatenada\"] = df[\"concatenada\"].apply(lambda x: str(x).replace(\"[\",\"\").replace(\"]\",\"\"))\n",
    "    df[\"concatenada\"] = df[\"concatenada\"].apply(lambda x: str(x).replace(\"'\",\"\"))\n",
    "    df[\"concatenada\"] = df[\"concatenada\"].apply(lambda x: str(x).replace(\",\",\" \"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "df = load_and_preprocess_data()\n",
    "print(f\"Dataset loaded with {len(df)} samples\")\n",
    "print(f\"Classes distribution:\")\n",
    "print(df['grupo_codificado'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef7bcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.text[item])\n",
    "        label = self.labels[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "599546bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Text Classifier with configurable parameters\n",
    "class BERTTextClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout_rate=0.3, hidden_layers=None):\n",
    "        super(BERTTextClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Optional additional hidden layers\n",
    "        if hidden_layers:\n",
    "            layers = []\n",
    "            prev_size = self.bert.config.hidden_size\n",
    "            for hidden_size in hidden_layers:\n",
    "                layers.extend([\n",
    "                    nn.Linear(prev_size, hidden_size),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(dropout_rate)\n",
    "                ])\n",
    "                prev_size = hidden_size\n",
    "            layers.append(nn.Linear(prev_size, n_classes))\n",
    "            self.classifier = nn.Sequential(*layers)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.classifier(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72d5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader function\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    \"\"\"Create DataLoader for the dataset\"\"\"\n",
    "    dataset = CustomDataset(\n",
    "        text=df[\"concatenada\"].to_numpy(),\n",
    "        labels=df[\"grupo_codificado\"].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=0,  # Set to 0 for Windows compatibility\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d204e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        total_samples += labels.size(0)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return correct_predictions.double() / total_samples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            total_samples += labels.size(0)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct_predictions.double() / total_samples\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    return accuracy, avg_loss, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54622fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Optuna optimization\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization\"\"\"\n",
    "    \n",
    "    # Start MLflow run for this trial\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Suggest hyperparameters\n",
    "        params = {\n",
    "            'max_len': trial.suggest_categorical('max_len', [128, 200, 256, 512]),\n",
    "            'batch_size': trial.suggest_categorical('batch_size', [8, 16, 32]),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True),\n",
    "            'epochs': trial.suggest_int('epochs', 4, 8),\n",
    "            'dropout_rate': trial.suggest_float('dropout_rate', 0.3, 0.5),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 0.1, 0.2),\n",
    "            'warmup_steps_ratio': trial.suggest_float('warmup_steps_ratio', 0.1, 0.2),\n",
    "            'use_scheduler': trial.suggest_categorical('use_scheduler', [True, False]),\n",
    "            'hidden_layers': trial.suggest_categorical('hidden_layers', [None, [512], [512, 256]])\n",
    "        }\n",
    "        \n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        try:\n",
    "            # Initialize tokenizer\n",
    "            tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "            \n",
    "            # Split data\n",
    "            df_train, df_val = train_test_split(\n",
    "                df, test_size=0.2, random_state=RANDOM_SEED, stratify=df['grupo_codificado']\n",
    "            )\n",
    "            \n",
    "            # Create data loaders\n",
    "            train_data_loader = create_data_loader(\n",
    "                df_train, tokenizer, params['max_len'], params['batch_size']\n",
    "            )\n",
    "            val_data_loader = create_data_loader(\n",
    "                df_val, tokenizer, params['max_len'], params['batch_size']\n",
    "            )\n",
    "            \n",
    "            # Initialize model\n",
    "            model = BERTTextClassifier(\n",
    "                n_classes=NCLASS, \n",
    "                dropout_rate=params['dropout_rate'],\n",
    "                hidden_layers=params['hidden_layers']\n",
    "            )\n",
    "            model = model.to(device)\n",
    "            \n",
    "            # Initialize optimizer and scheduler\n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(), \n",
    "                lr=params['learning_rate'],\n",
    "                weight_decay=params['weight_decay']\n",
    "            )\n",
    "            \n",
    "            scheduler = None\n",
    "            if params['use_scheduler']:\n",
    "                total_steps = len(train_data_loader) * params['epochs']\n",
    "                warmup_steps = int(total_steps * params['warmup_steps_ratio'])\n",
    "                scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=warmup_steps,\n",
    "                    num_training_steps=total_steps\n",
    "                )\n",
    "            \n",
    "            loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "            \n",
    "            # Training loop\n",
    "            best_val_accuracy = 0\n",
    "            \n",
    "            for epoch in range(params['epochs']):\n",
    "                # Training\n",
    "                train_acc, train_loss = train_epoch(\n",
    "                    model, train_data_loader, loss_fn, optimizer, device, scheduler\n",
    "                )\n",
    "                \n",
    "                # Validation\n",
    "                val_acc, val_loss, val_precision, val_recall, val_f1 = eval_model(\n",
    "                    model, val_data_loader, loss_fn, device\n",
    "                )\n",
    "                \n",
    "                # Log metrics for this epoch\n",
    "                mlflow.log_metrics({\n",
    "                    'train_accuracy': train_acc.item(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_accuracy': val_acc.item(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_precision': val_precision,\n",
    "                    'val_recall': val_recall,\n",
    "                    'val_f1': val_f1\n",
    "                }, step=epoch)\n",
    "                \n",
    "                # Update best validation accuracy\n",
    "                if val_acc > best_val_accuracy:\n",
    "                    best_val_accuracy = val_acc\n",
    "                \n",
    "                # Pruning: report intermediate value and check if trial should be pruned\n",
    "                trial.report(val_acc.item(), epoch)\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "            # Log final metrics\n",
    "            mlflow.log_metric('best_val_accuracy', best_val_accuracy.item())\n",
    "            \n",
    "            # Save model if it's among the best\n",
    "            if best_val_accuracy > 0.7:  # Save only good models\n",
    "                mlflow.pytorch.log_model(\n",
    "                    model, \n",
    "                    \"model\",\n",
    "                    registered_model_name=f\"BERT_Classifier_Trial_{trial.number}\"\n",
    "                )\n",
    "            \n",
    "            return best_val_accuracy.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            mlflow.log_param('error', str(e))\n",
    "            print(f\"Trial {trial.number} failed with error: {e}\")\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef474e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optuna study with MLflow integration\n",
    "def run_optimization():\n",
    "    \"\"\"Run hyperparameter optimization with Optuna and MLflow\"\"\"\n",
    "    \n",
    "    # Create MLflow callback for Optuna\n",
    "    mlflc = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(),\n",
    "        metric_name=\"best_val_accuracy\",\n",
    "        create_experiment=False\n",
    "    )\n",
    "    \n",
    "    # Create Optuna study\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=\"BERT_Hyperparameter_Optimization\",\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5,\n",
    "            n_warmup_steps=2,\n",
    "            interval_steps=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Start MLflow parent run\n",
    "    with mlflow.start_run(run_name=\"BERT_Hyperparameter_Optimization\"):\n",
    "        mlflow.log_param(\"n_trials\", N_TRIALS)\n",
    "        mlflow.log_param(\"sample_size\", SAMPLE_SIZE)\n",
    "        mlflow.log_param(\"n_classes\", NCLASS)\n",
    "        mlflow.log_param(\"pre_trained_model\", PRE_TRAINED_MODEL_NAME)\n",
    "        \n",
    "        # Run optimization\n",
    "        study.optimize(\n",
    "            objective, \n",
    "            n_trials=N_TRIALS,\n",
    "            callbacks=[mlflc],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # Log best parameters and results\n",
    "        best_params = study.best_params\n",
    "        best_value = study.best_value\n",
    "        \n",
    "        mlflow.log_params({f\"best_{k}\": v for k, v in best_params.items()})\n",
    "        mlflow.log_metric(\"best_accuracy\", best_value)\n",
    "        \n",
    "        print(f\"\\nOptimization completed!\")\n",
    "        print(f\"Best accuracy: {best_value:.4f}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        \n",
    "        return study, best_params, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63da09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization...\n",
      "Number of trials: 20\n",
      "Using device: cuda:0\n",
      "Dataset size: 500 samples\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cfeba655d54d93856443d260bac799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "Run with UUID 362ccf8b8b444339a335d9ac6bdfa85d is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m study, best_params, best_value \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m, in \u001b[0;36mrun_optimization\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_trained_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, PRE_TRAINED_MODEL_NAME)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmlflc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Log best parameters and results\u001b[39;00m\n\u001b[0;32m     39\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\jhoan\\Documents\\BERT_Model\\BERT_NLP\\.venv\\lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jhoan\\Documents\\BERT_Model\\BERT_NLP\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jhoan\\Documents\\BERT_Model\\BERT_NLP\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:172\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    170\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mget_trial(frozen_trial_id)\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[1;32m--> 172\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrozen_trial\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     elapsed_seconds \u001b[38;5;241m=\u001b[39m (datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m.\u001b[39mtotal_seconds()\n",
      "File \u001b[1;32mc:\\Users\\jhoan\\Documents\\BERT_Model\\BERT_NLP\\.venv\\lib\\site-packages\\optuna_integration\\mlflow\\mlflow.py:117\u001b[0m, in \u001b[0;36mMLflowCallback.__call__\u001b[1;34m(self, study, trial)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_experiment(study)\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_attrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRUN_ID_ATTRIBUTE_KEY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mlflow_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiment_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mlflow_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mlflow_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnested\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mlflow_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;66;03m# This sets the metrics for MLflow.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_metrics(trial\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;66;03m# This sets the params for MLflow.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jhoan\\Documents\\BERT_Model\\BERT_NLP\\.venv\\lib\\site-packages\\mlflow\\tracking\\fluent.py:380\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    378\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    381\u001b[0m         (\n\u001b[0;32m    382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    386\u001b[0m     )\n\u001b[0;32m    387\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID 362ccf8b8b444339a335d9ac6bdfa85d is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "print(f\"Number of trials: {N_TRIALS}\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "study, best_params, best_value = run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze optimization results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot optimization history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot optimization history\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study, ax=ax1)\n",
    "ax1.set_title('Optimization History')\n",
    "\n",
    "# Plot parameter importances\n",
    "optuna.visualization.matplotlib.plot_param_importances(study, ax=ax2)\n",
    "ax2.set_title('Parameter Importances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display trial results\n",
    "trials_df = study.trials_dataframe()\n",
    "print(\"\\nTop 10 trials:\")\n",
    "print(trials_df.nlargest(10, 'value')[['number', 'value', 'state']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "def train_final_model(best_params):\n",
    "    \"\"\"Train final model with best hyperparameters\"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"Final_Best_Model\"):\n",
    "        # Log best parameters\n",
    "        mlflow.log_params(best_params)\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        \n",
    "        # Split data (using larger validation set for final evaluation)\n",
    "        df_train, df_test = train_test_split(\n",
    "            df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['grupo_codificado']\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_data_loader = create_data_loader(\n",
    "            df_train, tokenizer, best_params['max_len'], best_params['batch_size']\n",
    "        )\n",
    "        test_data_loader = create_data_loader(\n",
    "            df_test, tokenizer, best_params['max_len'], best_params['batch_size']\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        model = BERTTextClassifier(\n",
    "            n_classes=NCLASS, \n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            hidden_layers=best_params['hidden_layers']\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Initialize optimizer and scheduler\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=best_params['learning_rate'],\n",
    "            weight_decay=best_params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = None\n",
    "        if best_params['use_scheduler']:\n",
    "            total_steps = len(train_data_loader) * best_params['epochs']\n",
    "            warmup_steps = int(total_steps * best_params['warmup_steps_ratio'])\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=warmup_steps,\n",
    "                num_training_steps=total_steps\n",
    "            )\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        # Training loop with progress tracking\n",
    "        print(\"Training final model with best parameters...\")\n",
    "        \n",
    "        for epoch in range(best_params['epochs']):\n",
    "            print(f\"Epoch {epoch + 1}/{best_params['epochs']}\")\n",
    "            \n",
    "            # Training\n",
    "            train_acc, train_loss = train_epoch(\n",
    "                model, train_data_loader, loss_fn, optimizer, device, scheduler\n",
    "            )\n",
    "            \n",
    "            # Testing\n",
    "            test_acc, test_loss, test_precision, test_recall, test_f1 = eval_model(\n",
    "                model, test_data_loader, loss_fn, device\n",
    "            )\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics({\n",
    "                'train_accuracy': train_acc.item(),\n",
    "                'train_loss': train_loss,\n",
    "                'test_accuracy': test_acc.item(),\n",
    "                'test_loss': test_loss,\n",
    "                'test_precision': test_precision,\n",
    "                'test_recall': test_recall,\n",
    "                'test_f1': test_f1\n",
    "            }, step=epoch)\n",
    "            \n",
    "            print(f\"  Train - Acc: {train_acc:.4f}, Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Test  - Acc: {test_acc:.4f}, Loss: {test_loss:.4f}, F1: {test_f1:.4f}\")\n",
    "        \n",
    "        # Save final model\n",
    "        mlflow.pytorch.log_model(\n",
    "            model, \n",
    "            \"final_model\",\n",
    "            registered_model_name=\"BERT_Text_Classifier_Final\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal model training completed!\")\n",
    "        print(f\"Final test accuracy: {test_acc:.4f}\")\n",
    "        print(f\"Final test F1-score: {test_f1:.4f}\")\n",
    "        \n",
    "        return model, test_acc.item(), test_f1\n",
    "\n",
    "# Train final model\n",
    "final_model, final_accuracy, final_f1 = train_final_model(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25550d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and model registry information\n",
    "print(\"=\" * 60)\n",
    "print(\"OPTIMIZATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total trials run: {len(study.trials)}\")\n",
    "print(f\"Best validation accuracy: {best_value:.4f}\")\n",
    "print(f\"Final test accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Final test F1-score: {final_f1:.4f}\")\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MLflow Tracking:\")\n",
    "print(f\"Experiment: {mlflow.get_experiment_by_name('BERT_Hyperparameter_Optimization').name}\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(\"\\nView your experiments in MLflow UI by running:\")\n",
    "print(\"mlflow ui\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT_NLP (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
